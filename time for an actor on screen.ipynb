{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame0.jpg', 'frame1.jpg', 'frame10.jpg', 'frame100.jpg', 'frame101.jpg', 'frame102.jpg', 'frame103.jpg', 'frame104.jpg', 'frame105.jpg', 'frame106.jpg', 'frame107.jpg', 'frame108.jpg', 'frame109.jpg', 'frame11.jpg', 'frame110.jpg', 'frame111.jpg', 'frame112.jpg', 'frame113.jpg', 'frame114.jpg', 'frame115.jpg', 'frame116.jpg', 'frame117.jpg', 'frame118.jpg', 'frame119.jpg', 'frame12.jpg', 'frame120.jpg', 'frame121.jpg', 'frame122.jpg', 'frame123.jpg', 'frame124.jpg', 'frame125.jpg', 'frame126.jpg', 'frame127.jpg', 'frame128.jpg', 'frame129.jpg', 'frame13.jpg', 'frame130.jpg', 'frame131.jpg', 'frame132.jpg', 'frame133.jpg', 'frame134.jpg', 'frame135.jpg', 'frame136.jpg', 'frame137.jpg', 'frame138.jpg', 'frame139.jpg', 'frame14.jpg', 'frame140.jpg', 'frame141.jpg', 'frame142.jpg', 'frame143.jpg', 'frame144.jpg', 'frame145.jpg', 'frame146.jpg', 'frame147.jpg', 'frame148.jpg', 'frame149.jpg', 'frame15.jpg', 'frame150.jpg', 'frame151.jpg', 'frame152.jpg', 'frame153.jpg', 'frame154.jpg', 'frame155.jpg', 'frame156.jpg', 'frame157.jpg', 'frame158.jpg', 'frame159.jpg', 'frame16.jpg', 'frame160.jpg', 'frame161.jpg', 'frame162.jpg', 'frame163.jpg', 'frame164.jpg', 'frame165.jpg', 'frame166.jpg', 'frame167.jpg', 'frame168.jpg', 'frame169.jpg', 'frame17.jpg', 'frame170.jpg', 'frame171.jpg', 'frame172.jpg', 'frame173.jpg', 'frame174.jpg', 'frame175.jpg', 'frame176.jpg', 'frame177.jpg', 'frame178.jpg', 'frame179.jpg', 'frame18.jpg', 'frame180.jpg', 'frame181.jpg', 'frame182.jpg', 'frame183.jpg', 'frame184.jpg', 'frame185.jpg', 'frame186.jpg', 'frame187.jpg', 'frame188.jpg', 'frame189.jpg', 'frame19.jpg', 'frame190.jpg', 'frame191.jpg', 'frame192.jpg', 'frame193.jpg', 'frame194.jpg', 'frame195.jpg', 'frame196.jpg', 'frame197.jpg', 'frame198.jpg', 'frame199.jpg', 'frame2.jpg', 'frame20.jpg', 'frame200.jpg', 'frame201.jpg', 'frame202.jpg', 'frame203.jpg', 'frame204.jpg', 'frame205.jpg', 'frame206.jpg', 'frame207.jpg', 'frame208.jpg', 'frame209.jpg', 'frame21.jpg', 'frame210.jpg', 'frame211.jpg', 'frame212.jpg', 'frame213.jpg', 'frame214.jpg', 'frame215.jpg', 'frame216.jpg', 'frame217.jpg', 'frame218.jpg', 'frame219.jpg', 'frame22.jpg', 'frame220.jpg', 'frame221.jpg', 'frame222.jpg', 'frame223.jpg', 'frame224.jpg', 'frame225.jpg', 'frame226.jpg', 'frame227.jpg', 'frame228.jpg', 'frame229.jpg', 'frame23.jpg', 'frame230.jpg', 'frame231.jpg', 'frame232.jpg', 'frame233.jpg', 'frame234.jpg', 'frame235.jpg', 'frame236.jpg', 'frame237.jpg', 'frame238.jpg', 'frame239.jpg', 'frame24.jpg', 'frame240.jpg', 'frame241.jpg', 'frame242.jpg', 'frame243.jpg', 'frame244.jpg', 'frame245.jpg', 'frame246.jpg', 'frame247.jpg', 'frame248.jpg', 'frame249.jpg', 'frame25.jpg', 'frame250.jpg', 'frame251.jpg', 'frame252.jpg', 'frame253.jpg', 'frame254.jpg', 'frame255.jpg', 'frame256.jpg', 'frame257.jpg', 'frame258.jpg', 'frame259.jpg', 'frame26.jpg', 'frame260.jpg', 'frame261.jpg', 'frame262.jpg', 'frame263.jpg', 'frame264.jpg', 'frame265.jpg', 'frame266.jpg', 'frame267.jpg', 'frame268.jpg', 'frame269.jpg', 'frame27.jpg', 'frame270.jpg', 'frame271.jpg', 'frame272.jpg', 'frame273.jpg', 'frame274.jpg', 'frame275.jpg', 'frame276.jpg', 'frame277.jpg', 'frame278.jpg', 'frame279.jpg', 'frame28.jpg', 'frame280.jpg', 'frame281.jpg', 'frame282.jpg', 'frame283.jpg', 'frame284.jpg', 'frame285.jpg', 'frame286.jpg', 'frame287.jpg', 'frame288.jpg', 'frame289.jpg', 'frame29.jpg', 'frame290.jpg', 'frame291.jpg', 'frame292.jpg', 'frame293.jpg', 'frame294.jpg', 'frame295.jpg', 'frame296.jpg', 'frame297.jpg', 'frame3.jpg', 'frame30.jpg', 'frame31.jpg', 'frame32.jpg', 'frame33.jpg', 'frame34.jpg', 'frame35.jpg', 'frame36.jpg', 'frame37.jpg', 'frame38.jpg', 'frame39.jpg', 'frame4.jpg', 'frame40.jpg', 'frame41.jpg', 'frame42.jpg', 'frame43.jpg', 'frame44.jpg', 'frame45.jpg', 'frame46.jpg', 'frame47.jpg', 'frame48.jpg', 'frame49.jpg', 'frame5.jpg', 'frame50.jpg', 'frame51.jpg', 'frame52.jpg', 'frame53.jpg', 'frame54.jpg', 'frame55.jpg', 'frame56.jpg', 'frame57.jpg', 'frame58.jpg', 'frame59.jpg', 'frame6.jpg', 'frame60.jpg', 'frame61.jpg', 'frame62.jpg', 'frame63.jpg', 'frame64.jpg', 'frame65.jpg', 'frame66.jpg', 'frame67.jpg', 'frame68.jpg', 'frame69.jpg', 'frame7.jpg', 'frame70.jpg', 'frame71.jpg', 'frame72.jpg', 'frame73.jpg', 'frame74.jpg', 'frame75.jpg', 'frame76.jpg', 'frame77.jpg', 'frame78.jpg', 'frame79.jpg', 'frame8.jpg', 'frame80.jpg', 'frame81.jpg', 'frame82.jpg', 'frame83.jpg', 'frame84.jpg', 'frame85.jpg', 'frame86.jpg', 'frame87.jpg', 'frame88.jpg', 'frame89.jpg', 'frame9.jpg', 'frame90.jpg', 'frame91.jpg', 'frame92.jpg', 'frame93.jpg', 'frame94.jpg', 'frame95.jpg', 'frame96.jpg', 'frame97.jpg', 'frame98.jpg', 'frame99.jpg', 'mapping', 'mapping.csv', 'test0.jpg', 'test1.jpg', 'test10.jpg', 'test100.jpg', 'test101.jpg', 'test102.jpg', 'test103.jpg', 'test104.jpg', 'test105.jpg', 'test106.jpg', 'test107.jpg', 'test108.jpg', 'test109.jpg', 'test11.jpg', 'test110.jpg', 'test111.jpg', 'test112.jpg', 'test113.jpg', 'test114.jpg', 'test115.jpg', 'test116.jpg', 'test117.jpg', 'test118.jpg', 'test119.jpg', 'test12.jpg', 'test120.jpg', 'test121.jpg', 'test122.jpg', 'test123.jpg', 'test124.jpg', 'test125.jpg', 'test126.jpg', 'test127.jpg', 'test128.jpg', 'test129.jpg', 'test13.jpg', 'test130.jpg', 'test131.jpg', 'test132.jpg', 'test133.jpg', 'test134.jpg', 'test135.jpg', 'test136.jpg', 'test137.jpg', 'test138.jpg', 'test139.jpg', 'test14.jpg', 'test140.jpg', 'test141.jpg', 'test142.jpg', 'test143.jpg', 'test144.jpg', 'test145.jpg', 'test146.jpg', 'test147.jpg', 'test148.jpg', 'test149.jpg', 'test15.jpg', 'test150.jpg', 'test151.jpg', 'test152.jpg', 'test153.jpg', 'test154.jpg', 'test155.jpg', 'test156.jpg', 'test157.jpg', 'test158.jpg', 'test159.jpg', 'test16.jpg', 'test160.jpg', 'test161.jpg', 'test162.jpg', 'test163.jpg', 'test164.jpg', 'test165.jpg', 'test166.jpg', 'test167.jpg', 'test168.jpg', 'test169.jpg', 'test17.jpg', 'test170.jpg', 'test171.jpg', 'test172.jpg', 'test173.jpg', 'test174.jpg', 'test175.jpg', 'test176.jpg', 'test177.jpg', 'test178.jpg', 'test179.jpg', 'test18.jpg', 'test180.jpg', 'test181.jpg', 'test182.jpg', 'test183.jpg', 'test184.jpg', 'test185.jpg', 'test19.jpg', 'test2.jpg', 'test20.jpg', 'test21.jpg', 'test22.jpg', 'test23.jpg', 'test24.jpg', 'test25.jpg', 'test26.jpg', 'test27.jpg', 'test28.jpg', 'test29.jpg', 'test3.jpg', 'test30.jpg', 'test31.jpg', 'test32.jpg', 'test33.jpg', 'test34.jpg', 'test35.jpg', 'test36.jpg', 'test37.jpg', 'test38.jpg', 'test39.jpg', 'test4.jpg', 'test40.jpg', 'test41.jpg', 'test42.jpg', 'test43.jpg', 'test44.jpg', 'test45.jpg', 'test46.jpg', 'test47.jpg', 'test48.jpg', 'test49.jpg', 'test5.jpg', 'test50.jpg', 'test51.jpg', 'test52.jpg', 'test53.jpg', 'test54.jpg', 'test55.jpg', 'test56.jpg', 'test57.jpg', 'test58.jpg', 'test59.jpg', 'test6.jpg', 'test60.jpg', 'test61.jpg', 'test62.jpg', 'test63.jpg', 'test64.jpg', 'test65.jpg', 'test66.jpg', 'test67.jpg', 'test68.jpg', 'test69.jpg', 'test7.jpg', 'test70.jpg', 'test71.jpg', 'test72.jpg', 'test73.jpg', 'test74.jpg', 'test75.jpg', 'test76.jpg', 'test77.jpg', 'test78.jpg', 'test79.jpg', 'test8.jpg', 'test80.jpg', 'test81.jpg', 'test82.jpg', 'test83.jpg', 'test84.jpg', 'test85.jpg', 'test86.jpg', 'test87.jpg', 'test88.jpg', 'test89.jpg', 'test9.jpg', 'test90.jpg', 'test91.jpg', 'test92.jpg', 'test93.jpg', 'test94.jpg', 'test95.jpg', 'test96.jpg', 'test97.jpg', 'test98.jpg', 'test99.jpg', 'testing', 'testing.csv', 'Tom and Jerry 3.mp4', 'Tom and jerry.mp4', 'weights.best.hdf5']\n",
      "Done!\n",
      "Done!\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Train on 208 samples, validate on 90 samples\n",
      "Epoch 1/100\n",
      "208/208 [==============================] - 22s 105ms/step - loss: 1.3026 - accuracy: 0.3606 - val_loss: 1.2228 - val_accuracy: 0.3889\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.22281, saving model to weights.best.hdf5\n",
      "Epoch 2/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 1.3142 - accuracy: 0.3558 - val_loss: 1.0745 - val_accuracy: 0.3667\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.22281 to 1.07453, saving model to weights.best.hdf5\n",
      "Epoch 3/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 1.1802 - accuracy: 0.3798 - val_loss: 1.0229 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.07453 to 1.02293, saving model to weights.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "208/208 [==============================] - 5s 24ms/step - loss: 1.1049 - accuracy: 0.4135 - val_loss: 0.9623 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02293 to 0.96235, saving model to weights.best.hdf5\n",
      "Epoch 5/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.9438 - accuracy: 0.5817 - val_loss: 0.8978 - val_accuracy: 0.5444\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.96235 to 0.89781, saving model to weights.best.hdf5\n",
      "Epoch 6/100\n",
      "208/208 [==============================] - 6s 30ms/step - loss: 0.8919 - accuracy: 0.6202 - val_loss: 0.7917 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.89781 to 0.79168, saving model to weights.best.hdf5\n",
      "Epoch 7/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.6886 - accuracy: 0.7404 - val_loss: 0.7022 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.79168 to 0.70221, saving model to weights.best.hdf5\n",
      "Epoch 8/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.5649 - accuracy: 0.7981 - val_loss: 0.6199 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.70221 to 0.61988, saving model to weights.best.hdf5\n",
      "Epoch 9/100\n",
      "208/208 [==============================] - 6s 30ms/step - loss: 0.4025 - accuracy: 0.8558 - val_loss: 0.5257 - val_accuracy: 0.8111\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.61988 to 0.52573, saving model to weights.best.hdf5\n",
      "Epoch 10/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.2890 - accuracy: 0.8990 - val_loss: 0.4495 - val_accuracy: 0.8111\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52573 to 0.44947, saving model to weights.best.hdf5\n",
      "Epoch 11/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.2121 - accuracy: 0.9567 - val_loss: 0.3858 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.44947 to 0.38576, saving model to weights.best.hdf5\n",
      "Epoch 12/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.1742 - accuracy: 0.9375 - val_loss: 0.3621 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.38576 to 0.36206, saving model to weights.best.hdf5\n",
      "Epoch 13/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.1160 - accuracy: 0.9856 - val_loss: 0.3290 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.36206 to 0.32898, saving model to weights.best.hdf5\n",
      "Epoch 14/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0745 - accuracy: 0.9904 - val_loss: 0.3640 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.32898\n",
      "Epoch 15/100\n",
      "208/208 [==============================] - 6s 28ms/step - loss: 0.0609 - accuracy: 0.9856 - val_loss: 0.3249 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.32898 to 0.32493, saving model to weights.best.hdf5\n",
      "Epoch 16/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0520 - accuracy: 0.9904 - val_loss: 0.3363 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.32493\n",
      "Epoch 17/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.0422 - accuracy: 0.9904 - val_loss: 0.3614 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.32493\n",
      "Epoch 18/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.0387 - accuracy: 0.9904 - val_loss: 0.3716 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.32493\n",
      "Epoch 19/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.0356 - accuracy: 0.9904 - val_loss: 0.3483 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.32493\n",
      "Epoch 20/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.0309 - accuracy: 0.9952 - val_loss: 0.3501 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.32493\n",
      "Epoch 21/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0349 - accuracy: 0.9952 - val_loss: 0.4193 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.32493\n",
      "Epoch 22/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.3411 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.32493\n",
      "Epoch 23/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0244 - accuracy: 0.9904 - val_loss: 0.3224 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.32493 to 0.32242, saving model to weights.best.hdf5\n",
      "Epoch 24/100\n",
      "208/208 [==============================] - 7s 33ms/step - loss: 0.0301 - accuracy: 0.9904 - val_loss: 0.3861 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.32242\n",
      "Epoch 25/100\n",
      "208/208 [==============================] - 9s 42ms/step - loss: 0.0260 - accuracy: 0.9904 - val_loss: 0.4233 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.32242\n",
      "Epoch 26/100\n",
      "208/208 [==============================] - 7s 35ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.32242\n",
      "Epoch 27/100\n",
      "208/208 [==============================] - 7s 35ms/step - loss: 0.0183 - accuracy: 0.9904 - val_loss: 0.3821 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.32242\n",
      "Epoch 28/100\n",
      "208/208 [==============================] - 9s 44ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 0.3617 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.32242\n",
      "Epoch 29/100\n",
      "208/208 [==============================] - 9s 43ms/step - loss: 0.0243 - accuracy: 0.9904 - val_loss: 0.3677 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.32242\n",
      "Epoch 30/100\n",
      "208/208 [==============================] - 6s 29ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.3389 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32242\n",
      "Epoch 31/100\n",
      "208/208 [==============================] - 7s 35ms/step - loss: 0.0255 - accuracy: 0.9904 - val_loss: 0.4798 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32242\n",
      "Epoch 32/100\n",
      "208/208 [==============================] - 8s 39ms/step - loss: 0.0270 - accuracy: 0.9904 - val_loss: 0.4521 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.32242\n",
      "Epoch 33/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.32242\n",
      "Epoch 34/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.3489 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.32242\n",
      "Epoch 35/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.4166 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.32242\n",
      "Epoch 36/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.32242\n",
      "Epoch 37/100\n",
      "208/208 [==============================] - 6s 29ms/step - loss: 0.0167 - accuracy: 0.9904 - val_loss: 0.5065 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.32242\n",
      "Epoch 38/100\n",
      "208/208 [==============================] - 6s 30ms/step - loss: 0.0344 - accuracy: 0.9952 - val_loss: 0.4114 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.32242\n",
      "Epoch 39/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0161 - accuracy: 0.9904 - val_loss: 0.3769 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.32242\n",
      "Epoch 40/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.32242\n",
      "Epoch 41/100\n",
      "208/208 [==============================] - 6s 28ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.3678 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.32242\n",
      "Epoch 42/100\n",
      "208/208 [==============================] - 6s 28ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.32242\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 6s 30ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.32242\n",
      "Epoch 44/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0214 - accuracy: 0.9952 - val_loss: 0.3797 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.32242\n",
      "Epoch 45/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0090 - accuracy: 0.9952 - val_loss: 0.3679 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.32242\n",
      "Epoch 46/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0231 - accuracy: 0.9952 - val_loss: 0.4076 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.32242\n",
      "Epoch 47/100\n",
      "208/208 [==============================] - 6s 28ms/step - loss: 0.0180 - accuracy: 0.9904 - val_loss: 0.4268 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.32242\n",
      "Epoch 48/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0169 - accuracy: 0.9904 - val_loss: 0.3999 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.32242\n",
      "Epoch 49/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.4070 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.32242\n",
      "Epoch 50/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0174 - accuracy: 0.9952 - val_loss: 0.3925 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.32242\n",
      "Epoch 51/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.4030 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.32242\n",
      "Epoch 52/100\n",
      "208/208 [==============================] - 6s 28ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.32242\n",
      "Epoch 53/100\n",
      "208/208 [==============================] - 6s 28ms/step - loss: 0.0100 - accuracy: 0.9952 - val_loss: 0.4083 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.32242\n",
      "Epoch 54/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.4217 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.32242\n",
      "Epoch 55/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.3627 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.32242\n",
      "Epoch 56/100\n",
      "208/208 [==============================] - 6s 29ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.32242\n",
      "Epoch 57/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.4238 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.32242\n",
      "Epoch 58/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0223 - accuracy: 0.9904 - val_loss: 0.4733 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.32242\n",
      "Epoch 59/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.32242\n",
      "Epoch 60/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.0200 - accuracy: 0.9952 - val_loss: 0.4045 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.32242\n",
      "Epoch 61/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 0.4583 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.32242\n",
      "Epoch 62/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.32242\n",
      "Epoch 63/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.32242\n",
      "Epoch 64/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0128 - accuracy: 0.9952 - val_loss: 0.4315 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.32242\n",
      "Epoch 65/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.32242\n",
      "Epoch 66/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.3823 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.32242\n",
      "Epoch 67/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0212 - accuracy: 0.9904 - val_loss: 0.3875 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.32242\n",
      "Epoch 68/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0096 - accuracy: 0.9952 - val_loss: 0.3860 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.32242\n",
      "Epoch 69/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.5090 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.32242\n",
      "Epoch 70/100\n",
      "208/208 [==============================] - 6s 28ms/step - loss: 0.0164 - accuracy: 0.9904 - val_loss: 0.5415 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.32242\n",
      "Epoch 71/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0080 - accuracy: 0.9952 - val_loss: 0.5230 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.32242\n",
      "Epoch 72/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0158 - accuracy: 0.9904 - val_loss: 0.4641 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.32242\n",
      "Epoch 73/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.32242\n",
      "Epoch 74/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0099 - accuracy: 0.9904 - val_loss: 0.5647 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.32242\n",
      "Epoch 75/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.4346 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.32242\n",
      "Epoch 76/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0244 - accuracy: 0.9952 - val_loss: 0.4370 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.32242\n",
      "Epoch 77/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0094 - accuracy: 0.9952 - val_loss: 0.4505 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.32242\n",
      "Epoch 78/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0216 - accuracy: 0.9904 - val_loss: 0.4155 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.32242\n",
      "Epoch 79/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0170 - accuracy: 0.9904 - val_loss: 0.4243 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.32242\n",
      "Epoch 80/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0187 - accuracy: 0.9952 - val_loss: 0.3961 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.32242\n",
      "Epoch 81/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0089 - accuracy: 0.9952 - val_loss: 0.4071 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.32242\n",
      "Epoch 82/100\n",
      "208/208 [==============================] - 6s 29ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.4641 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.32242\n",
      "Epoch 83/100\n",
      "208/208 [==============================] - 7s 32ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.4651 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.32242\n",
      "Epoch 84/100\n",
      "208/208 [==============================] - 8s 39ms/step - loss: 0.0125 - accuracy: 0.9904 - val_loss: 0.4787 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00084: val_loss did not improve from 0.32242\n",
      "Epoch 85/100\n",
      "208/208 [==============================] - 7s 35ms/step - loss: 0.0079 - accuracy: 0.9952 - val_loss: 0.4913 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.32242\n",
      "Epoch 86/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0096 - accuracy: 0.9952 - val_loss: 0.4497 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.32242\n",
      "Epoch 87/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.4580 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.32242\n",
      "Epoch 88/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0054 - accuracy: 0.9952 - val_loss: 0.4163 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.32242\n",
      "Epoch 89/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0129 - accuracy: 0.9904 - val_loss: 0.4096 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.32242\n",
      "Epoch 90/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0060 - accuracy: 0.9952 - val_loss: 0.4352 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.32242\n",
      "Epoch 91/100\n",
      "208/208 [==============================] - 6s 29ms/step - loss: 0.0156 - accuracy: 0.9904 - val_loss: 0.5076 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.32242\n",
      "Epoch 92/100\n",
      "208/208 [==============================] - 8s 37ms/step - loss: 0.0105 - accuracy: 0.9952 - val_loss: 0.5048 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.32242\n",
      "Epoch 93/100\n",
      "208/208 [==============================] - 7s 33ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.4445 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.32242\n",
      "Epoch 94/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.4246 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.32242\n",
      "Epoch 95/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0111 - accuracy: 0.9952 - val_loss: 0.4612 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.32242\n",
      "Epoch 96/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.32242\n",
      "Epoch 97/100\n",
      "208/208 [==============================] - 5s 25ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.4534 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.32242\n",
      "Epoch 98/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.32242\n",
      "Epoch 99/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0196 - accuracy: 0.9904 - val_loss: 0.4552 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.32242\n",
      "Epoch 100/100\n",
      "208/208 [==============================] - 5s 26ms/step - loss: 0.0160 - accuracy: 0.9904 - val_loss: 0.4671 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.32242\n",
      "6\n",
      "186/186 [==============================] - 1s 3ms/step\n",
      "accuracy: 65.59%\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#%matplotlib inline\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import os \n",
    "directory = r'E:\\video classification'\n",
    "os.chdir(directory) \n",
    "print(os.listdir(directory))\n",
    "count = 0\n",
    "videoFile = \"Tom and jerry.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"frame%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "videoFile = \"Tom and Jerry 3.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")\n",
    "data = pd.read_csv('mapping.csv')\n",
    "test = pd.read_csv('testing.csv')\n",
    "print (\"1\")\n",
    "X = []\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    X.append(img)\n",
    "X = np.array(X)\n",
    "\n",
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)\n",
    "print (\"2\")\n",
    "from keras.utils import np_utils\n",
    "train_y = np_utils.to_categorical(data.Class)\n",
    "test_y = np_utils.to_categorical(test.Class)\n",
    "\n",
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224,3)).astype(int)\n",
    "    image.append(a)\n",
    "X = np.array(image)\n",
    "\n",
    "test_image = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)\n",
    "print (\"3\")\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X, mode='tf')\n",
    "test_image = preprocess_input(test_image, mode='tf')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, train_y, test_size=0.3, random_state=42)\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "test_image = base_model.predict(test_image)\n",
    "\n",
    "X_train = X_train.reshape(208, 7*7*512)\n",
    "X_valid = X_valid.reshape(90, 7*7*512)\n",
    "test_image = test_image.reshape(186, 7*7*512)\n",
    "print (\"4\")\n",
    "train = X_train/X_train.max()\n",
    "X_valid = X_valid/X_train.max()\n",
    "test_image = test_image/test_image.max()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid'))   # hidden layer\n",
    "model.add(Dropout(0.5))      # adding dropout\n",
    "model.add(Dense(units=512, activation='sigmoid'))    # hidden layer\n",
    "model.add(Dropout(0.5))      # adding dropout\n",
    "model.add(Dense(units=256, activation='sigmoid'))    # hidden layer\n",
    "model.add(Dropout(0.5))      # adding dropout\n",
    "model.add(Dense(3, activation='softmax'))            # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print (\"5\")\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "class_weights = compute_class_weight('balanced',np.unique(data.Class), data.Class)  # computing weights of different classes\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]      # model check pointing based on validation loss\n",
    "\n",
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid), class_weight=class_weights, callbacks=callbacks_list)\n",
    "print (\"6\")\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "scores = model.evaluate(test_image, test_y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print (\"7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
